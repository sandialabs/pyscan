# -*- coding: utf-8 -*-
import h5py
import pickle
import json
from pathlib import Path
from pyscan.general.item_attribute import ItemAttribute
from pyscan.general.pyscan_json_decoder import PyscanJSONDecoder


def load_experiment(file_name):
    '''
    Function to load experimental data created by pyscan

    Parameters
    ----------
    file_name : str
        Path to file that is to be loaded

    '''
    if '.pkl' in file_name:
        data_version = 0.1
    elif '.hdf5' in file_name:
        data_version = 0.2
    else:
        file_path = Path(file_name)
        if file_path.with_suffix('.pkl').is_file():
            data_version = 0.1
        elif file_path.with_suffix('.hdf5').is_file():
            data_version = 0.2
            file_name += '.hdf5'
        else:
            assert 0, 'Cannot locate {}'.format(file_name)

    if data_version == 0.1:
        meta_data = pickle.load(
            open('{}.pkl'.format(file_name), "rb"))

        expt = ItemAttribute()
        expt.runinfo = ItemAttribute()
        expt.devices = ItemAttribute()

        for key, value in meta_data['runinfo'].items():
            expt.runinfo[key] = value

        for key, value in meta_data['devices'].items():
            expt.devices[key] = value

        data = h5py.File('{}.hdf5'.format(file_name), 'r')
        with h5py.File('{}.hdf5'.format(file_name), 'r') as f:
            for key, value in data.items():
                expt[key] = (f[key][:]).astype('float64')

        return expt

    elif data_version == 0.2:
        expt = ItemAttribute()
        expt.runinfo = ItemAttribute()
        expt.devices = ItemAttribute()

        f = h5py.File('{}'.format(file_name), 'r')
        expt.runinfo = json.loads(f.attrs['runinfo'], cls=PyscanJSONDecoder)

        expt.devices = json.loads(f.attrs['devices'], cls=PyscanJSONDecoder)

        for key, value in f.items():
            expt[key] = (f[key][:]).astype('float64')
        all_datasets = [key for key in f.keys()]
        expt.runinfo.measured = find_measured_datasets(expt.runinfo, all_datasets)
        f.close()

        return expt


def find_measured_datasets(runinfo, all_datasets):
    """
    HDF5 files contain two types of datasets.  Measured datasets are data from
    the measure_function, and while running a list of measured datasets is
    included in runinfo.measured. Pyscan generated datasets are created when
    the experiment runs. This function identifies the generated dataset from
    each scan.

    Returns:
        List of datasets generated by pyscan.
    """
    generated = []
    i = 0
    scan_id = f"scan{i}"
    while hasattr(runinfo, scan_id):
        # currently only scan0 ... scan3 are used, but future-proof this by
        # looking at up to a scan number of 10.
        try:
            # early stop/save or crashed files don't have device names, so
            # just return
            device_names = runinfo[scan_id].device_names
            if hasattr(runinfo[scan_id], "prop"):
                prop = runinfo[scan_id].prop
                if prop:
                    for device in device_names:
                        generated.append(f"{device}_{prop}")
                else:
                    # remaining scans are empty when 'prop': None
                    break
            else:
                # RepeatScan, AverageScan, FunctionScan
                for device in device_names:
                    generated.append(device)
        except AttributeError:
            break
        i += 1
        scan_id = f"scan{i}"

    measured = set(all_datasets).symmetric_difference(generated)

    return list(measured)
